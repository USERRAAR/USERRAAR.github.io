{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "(Preprocess Step 1) Download MA-Reuters"
      ],
      "metadata": {
        "id": "EhRBlCDgzFHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /root/nltk_data/corpora/ && wget https://www.kde.cs.tut.ac.jp/~aono/data/ma_reuters.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bIXbHyncQNj",
        "outputId": "bc70d9a5-ec55-427a-9e79-57254738e664"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-13 12:50:51--  https://www.kde.cs.tut.ac.jp/~aono/data/ma_reuters.zip\n",
            "Resolving www.kde.cs.tut.ac.jp (www.kde.cs.tut.ac.jp)... 133.15.24.10\n",
            "Connecting to www.kde.cs.tut.ac.jp (www.kde.cs.tut.ac.jp)|133.15.24.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6369593 (6.1M) [application/zip]\n",
            "Saving to: ‘ma_reuters.zip.1’\n",
            "\n",
            "ma_reuters.zip.1    100%[===================>]   6.07M  2.87MB/s    in 2.1s    \n",
            "\n",
            "2023-02-13 12:50:54 (2.87 MB/s) - ‘ma_reuters.zip.1’ saved [6369593/6369593]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Preprocess Step 2) Installing NLTK"
      ],
      "metadata": {
        "id": "3Ix2fqmbzpn4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aysN2FqRbC0Q"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Preprocess Step 3) Installing Scikit-Learn"
      ],
      "metadata": {
        "id": "PNMVr0NCz8qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2IwErAFbDjI",
        "outputId": "00224824-1c30-4b00-dc4a-e8899a1d33d5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Step 1) Sample Program & Modifying Category"
      ],
      "metadata": {
        "id": "0TJoQ9Yx0Yz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.util import LazyCorpusLoader\n",
        "from nltk.corpus.reader import *\n",
        "\n",
        "# Loading the corpus\n",
        "ma_reuters = LazyCorpusLoader(\n",
        "    'ma_reuters', CategorizedPlaintextCorpusReader, '(training|test).*',\n",
        "    cat_file='cats.txt', encoding='ISO-8859-2')\n",
        "\n",
        "# Load MA_Reuters\n",
        "documents = ma_reuters.fileids()\n",
        "print (str(len(documents)) + \" total articles\")\n",
        "\n",
        "# extracting training and testing data (document ID)\n",
        "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), documents))\n",
        "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
        "print (str(len(train_docs_id)) + \" training data\")\n",
        "print (str(len(test_docs_id)) + \" testing data\")\n",
        "\n",
        "# Training and testing data\n",
        "train_docs = [ma_reuters.raw(doc_id) for doc_id in train_docs_id]\n",
        "test_docs = [ma_reuters.raw(doc_id) for doc_id in test_docs_id]\n",
        " \n",
        "# print the total number of categories\n",
        "categories = ma_reuters.categories()\n",
        "num_categories = len(categories)\n",
        "print (num_categories, \" categories\")\n",
        "print (categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2MXiDEabEvu",
        "outputId": "29b02010-7b2f-43a8-c8d0-4dae1601cf5e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10700 total articles\n",
            "7713 training data\n",
            "2987 testing data\n",
            "55  categories\n",
            "['acq', 'alum', 'barley', 'bop', 'carcass', 'cocoa', 'coffee', 'copper', 'corn', 'cotton', 'cpi', 'crude', 'dlr', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'hog', 'housing', 'interest', 'ipi', 'iron-steel', 'jobs', 'lead', 'livestock', 'meal-feed', 'money-fx', 'money-supply', 'nat-gas', 'oilseed', 'orange', 'palm-oil', 'pet-chem', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifying Catagory to Cocoa\n",
        "# Documents in a category\n",
        "category_docs = ma_reuters.fileids(\"cocoa\");\n",
        "document_id = category_docs[0] # The first document\n",
        "# print the inside document\n",
        "print (ma_reuters.raw(document_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB5mUyccj1WD",
        "outputId": "240cd172-fdc2-4152-a97f-1aaabee531f4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COCOA EXPORTERS EXPECTED TO LIMIT SALES\n",
            "  Major cocoa exporters are likely to\n",
            "  limit sales in the weeks ahead in an effort to boost world\n",
            "  prices, sources close to a meeting of the Cocoa Producers\n",
            "  Alliance (CPA) said.\n",
            "      The sources said the depressed world market had been one of\n",
            "  the main topics discussed in a closed door meeting of the\n",
            "  11-member CPA which began on Monday.\n",
            "      They said producers agreed that cutting sales would aid the\n",
            "  buffer stock manager of a new international cocoa pact in his\n",
            "  effort to support prices.\n",
            "      Major cocoa producing and consuming nations agreed\n",
            "  operation rules for the buffer stock at a meeting in London\n",
            "  last month and the stock manager is expected to enter the\n",
            "  market soon.\n",
            "      Prices, under the weight of three successive cocoa\n",
            "  surpluses, recently fell to the level at which the manager has\n",
            "  to buy cocoa under stock rules.\n",
            "      The buffer stock aims to keep prices within a pre-set range\n",
            "  by buying when prices fall and selling when they rise.\n",
            "      \"The world's cocoa price at present is just not interesting,\"\n",
            "  commented one delegate representing a major CPA producer.\n",
            "      Another source said that with much of the 1986/87\n",
            "  (October-September) world cocoa crop sold, limiting sales in\n",
            "  the near term concerns essentially next year's harvest.\n",
            "      The sources noted, however, that the cocoa industry in\n",
            "  Brazil, the world's number two producer, is in private hands.\n",
            "  This means limiting sales is more difficult than in major West\n",
            "  African producers, where sales are made or authorized by\n",
            "  commodity marketing boards.\n",
            "      The CPA includes the world's top three producers, Ivory\n",
            "  Coast, Brazil and Ghana, and accounts for 80 pct of all output.\n",
            "      The meeting here is due to end tomorrow evening.\n",
            "  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization with NLTK, TF-IDF vectorizer with scikit-learn\n",
        "from nltk import word_tokenize\n",
        "import re # regular expression\n",
        " \n",
        "def tokenize(text): # returning tokens\n",
        "    min_length = 3\n",
        "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
        "\n",
        "    p = re.compile('[a-zA-Z]+')\n",
        "    filtered_tokens = list(filter (lambda token: p.match(token) and len(token) >= min_length, words))\n",
        "    return filtered_tokens\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=tokenize)\n",
        "# fit_transform\n",
        "vectorised_train_documents = vectorizer.fit_transform(train_docs)\n",
        "# transform\n",
        "vectorised_test_documents = vectorizer.transform(test_docs)\n",
        "print(\"converted to TF-IF model\")\n",
        "print(\"training document dimension ：\",vectorised_train_documents.shape)\n",
        "print(\"testing document dimension：\",vectorised_test_documents.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXunI4CSkPZv",
        "outputId": "ed03c10a-3ec0-44e2-a28d-000d7c9cb642"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converted to TF-IF model\n",
            "training document dimension ： (7713, 26978)\n",
            "testing document dimension： (2987, 26978)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM classification\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "import numpy as np\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "train_labels = mlb.fit_transform([ma_reuters.categories(doc_id) \\\n",
        "                             for doc_id in train_docs_id])\n",
        "test_labels = mlb.transform([ma_reuters.categories(doc_id) \\\n",
        "                             for doc_id in test_docs_id])\n",
        "# 木内的代码在这里多一个print\n",
        "\n",
        "#  multi-class, mult-label classification + unknown class prediction\n",
        "OVR_classifier = OneVsRestClassifier(LinearSVC(random_state=41)) \n",
        "OVR_classifier.fit(vectorised_train_documents, train_labels)\n",
        "OVR_predictions = OVR_classifier.predict(vectorised_test_documents)\n",
        "\n",
        "# Jaccard coefficient\n",
        "print (f\"Jaccard coeeficients:\"\n",
        "    f\"{np.round(jaccard_score(test_labels,OVR_predictions, average='samples'),3)}\")\n",
        "\n",
        "# Hamming loss Calculate \n",
        "print (f\"Hamming loss:\"\n",
        "    f\"{np.round(hamming_loss(test_labels,OVR_predictions),3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Nx3pxslJCJ",
        "outputId": "0f5ecf93-4f85-44a9-bf37-9cf4c0bbc255"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard coeeficients:0.86\n",
            "Hamming loss:0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Step 2) Evaluate The Category"
      ],
      "metadata": {
        "id": "XuiQxvrO3gqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#以下为木内在原SVM代码段的补充代码\n",
        "print(\"Category: Jaccard Calculate score\")\n",
        "max = [-1  ,[\"\"]]\n",
        "min = [1000,[\"\"]]\n",
        "for category, jscore in zip(categories, jaccard_score(test_labels,OVR_predictions, average=None)):\n",
        "    if max[0]<jscore:\n",
        "        max = [jscore, [category]]\n",
        "    elif max[0] == jscore:\n",
        "        max[1].append(category)\n",
        "    \n",
        "    if min[0]> jscore:\n",
        "        min = [jscore, [category]]\n",
        "    elif min[0] == jscore:\n",
        "        min[1].append(category)\n",
        "\n",
        "print(f\"max: {max[1]} : {max[0]}\")\n",
        "print(f\"min: {min[1]} : {min[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6KyMACx31xu",
        "outputId": "62459060-5d46-4a4c-c30a-84eab6d835a0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category: Jaccard Calculate score\n",
            "max: ['earn'] : 0.9690627843494085\n",
            "min: ['lead', 'pet-chem', 'soy-oil', 'strategic-metal', 'yen'] : 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Step 3) Senpai Method"
      ],
      "metadata": {
        "id": "ln7gv4Hd4H8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USB3ntgD4ne4",
        "outputId": "bebb8302-6d2d-43d1-eb14-95b3b9f72ee5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "\n",
        "def split_docs(docs: list):\n",
        "    return [list(filter(None, re.split('[ \\n]',td))) for td in docs]\n",
        "\n",
        "\n",
        "class LabeledListSentence(object):\n",
        "    def __init__(self, words_list, labels):\n",
        "        self.words_list = words_list\n",
        "        self.labels = labels\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i, words in enumerate(self.words_list):\n",
        "            yield models.doc2vec.TaggedDocument(words, [self.labels[i]])"
      ],
      "metadata": {
        "id": "Qsedbb0Y4LvC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splited_train_docs = split_docs(train_docs)\n",
        "splited_test_docs = split_docs(test_docs)\n",
        "\n",
        "train_labels_text = [ma_reuters.categories(doc_id) for doc_id in train_docs_id]\n",
        "print(len(train_labels_text), len(splited_train_docs))\n",
        "\n",
        "train_sentences = [models.doc2vec.TaggedDocument(words, label) for words,label in zip(splited_train_docs, train_labels_text)]\n",
        "\n",
        "\n",
        "model = models.Doc2Vec(documents=train_sentences,vector_size=2000, window=2, min_count=1, workers=4)\n",
        "\n",
        "\n",
        "model.save('doc2vec.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUqJlG9I4hqH",
        "outputId": "f89e1316-cde0-498d-b4bd-2062652f91b4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7713 7713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "\n",
        "# Load a model from a file after learning\n",
        "\n",
        "model = models.Doc2Vec.load('doc2vec.model') # Above mentioned models\n",
        "\n",
        "train_vec_list = []\n",
        "for docs in splited_train_docs:\n",
        "    train_vec_list.append(model.infer_vector(docs))\n",
        "train_vec = np.array(train_vec_list)\n",
        "\n",
        "test_vec_list = []\n",
        "for docs in splited_test_docs:\n",
        "    test_vec_list.append(model.infer_vector(docs))\n",
        "test_vec = np.array(test_vec_list)\n",
        "\n",
        "\n",
        "\n",
        "# Training + prediction with multi label classifier\n",
        "OVR_classifier = OneVsRestClassifier(LinearSVC(random_state=41)) \n",
        "OVR_classifier.fit(train_vec, train_labels)\n",
        "\n",
        "OVR_predictions = OVR_classifier.predict(test_vec)\n",
        "\n",
        "# Jaccard coefficient\n",
        "print (f\"Jaccard coeeficients:\"\n",
        "    f\"{np.round(jaccard_score(test_labels,OVR_predictions, average='samples'),3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdK5CeLL4kvO",
        "outputId": "93473870-e356-4ca3-a59c-f4204e869766"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard coeeficients:0.65\n"
          ]
        }
      ]
    }
  ]
}